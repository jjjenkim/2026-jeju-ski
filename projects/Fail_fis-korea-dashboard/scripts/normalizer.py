#!/usr/bin/env python3
"""
FIS ë°ì´í„° ì •ê·œí™” ìŠ¤í¬ë¦½íŠ¸ (build-time normalization)
ëª©ì : raw JSON ë°ì´í„°ë“¤ì„ ê²€ì¦í•˜ê³  ë‹¨ì¼ CSV íŒŒì¼ë¡œ í†µí•©
"""

import json
import pandas as pd
from pathlib import Path
from datetime import datetime
import re
import sys

def load_athlete_master():
    """ì„ ìˆ˜ ë§ˆìŠ¤í„° ì •ë³´ ë¡œë“œ"""
    master_path = Path("scripts/athletes-master.json")
    if not master_path.exists():
        print("âŒ athletes-master.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}
    
    athletes = json.loads(master_path.read_text())
    # FIS Codeë¥¼ í‚¤ë¡œ í•˜ëŠ” ë§µ ìƒì„±
    return {str(a['competitorId']): a for a in athletes}

def validate_data(df):
    """ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
    print("\nğŸ§ ë°ì´í„° ê²€ì¦ ì‹œì‘...")
    
    issues = []
    
    # 1. FIS Code í˜•ì‹ í™•ì¸ (6ìë¦¬ ìˆ«ì)
    if 'fis_code' not in df.columns:
         issues.append("fis_code ì»¬ëŸ¼ ì—†ìŒ")
    
    # 2. ë‚ ì§œ í˜•ì‹ í™•ì¸
    invalid_dates = pd.to_datetime(df['date'], errors='coerce').isna()
    if invalid_dates.sum() > 0:
        issues.append(f"âŒ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {invalid_dates.sum()}ê±´")
    
    # 3. ë¯¸ë˜ ë°ì´í„° í™•ì¸
    today = datetime.now()
    dates = pd.to_datetime(df['date'], errors='coerce')
    future_dates = dates > today
    if future_dates.sum() > 0:
        issues.append(f"âš ï¸ ë¯¸ë˜ ë‚ ì§œ ë°ì´í„° ë°œê²¬: {future_dates.sum()}ê±´")
        
    if not issues:
        print("âœ… ë°ì´í„° ê²€ì¦ í†µê³¼!")
    else:
        for issue in issues:
            print(issue)
            
    return df

def normalize_all():
    """ì „ì²´ ë¡œì§ ì‹¤í–‰"""
    
    athlete_map = load_athlete_master()
    
    raw_dir = Path("data/raw")
    if not raw_dir.exists():
        print("âŒ data/raw ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. scraper.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        sys.exit(1)
        
    json_files = list(raw_dir.glob("*.json"))
    if not json_files:
        print("âŒ ì²˜ë¦¬í•  JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    print(f"ğŸ“Š ì´ {len(json_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
    
    all_results = []
    
    for json_file in json_files:
        try:
            data = json.loads(json_file.read_text())
            athlete_name = data.get('athlete')
            
            # íŒŒì¼ëª… íŒŒì‹±: raw_{name}_{id}.json
            match = re.search(r'raw_.*_(\d+)\.json', json_file.name)
            if match:
                fis_code = match.group(1)
            else:
                fis_code = "Unknown"
                
            for result in data.get('results', []):
                row = {
                    'athlete': athlete_name,
                    'fis_code': fis_code,
                    'date': result.get('date'),
                    'location': result.get('location'),
                    'nation': result.get('nation'),
                    'category': result.get('category'),
                    'discipline': result.get('discipline'),
                    'rank': result.get('rank'),
                    'fis_points': result.get('fis_points'),
                    'cup_points': result.get('cup_points')
                }
                all_results.append(row)
                
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ {json_file.name}: {e}")

    df = pd.DataFrame(all_results)
    
    # íŠ¸ë¦¼ ì²˜ë¦¬
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = df[col].str.strip()

    # ë‚ ì§œ ì •ê·œí™” (DD-MM-YYYY -> YYYY-MM-DD)
    df['date_obj'] = pd.to_datetime(df['date'], format='%d-%m-%Y', errors='coerce')
    
    df = df.dropna(subset=['date_obj'])
    df['date'] = df['date_obj'].dt.strftime('%Y-%m-%d')
    
    # ì •ë ¬: ë‚ ì§œ ìµœì‹ ìˆœ
    df = df.sort_values(by='date', ascending=False)
    
    # ì¤‘ë³µ ì œê±°
    df = df.drop_duplicates(subset=['fis_code', 'date', 'category', 'discipline'], keep='first')
    
    # ê²€ì¦
    validate_data(df)
    
    # CSV ì €ì¥
    output_dir = Path("public/data")
    output_dir.mkdir(exist_ok=True, parents=True)
    output_path = output_dir / "fis_all_results.csv"
    
    cols = ['athlete', 'fis_code', 'date', 'location', 'nation', 'category', 'discipline', 'rank', 'fis_points', 'cup_points']
    df[cols].to_csv(output_path, index=False, encoding='utf-8-sig')
    
    print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"   ì´ ë°ì´í„°: {len(df)}í–‰")
    print(f"   íŒŒì¼ í¬ê¸°: {output_path.stat().st_size / 1024:.1f} KB")

if __name__ == '__main__':
    normalize_all()
