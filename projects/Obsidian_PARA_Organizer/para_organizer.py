#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Obsidian PARA Organizer
ì˜µì‹œë””ì–¸ ë³¼íŠ¸ë¥¼ PARA + ì œí…”ì¹´ìŠ¤í… êµ¬ì¡°ë¡œ ìë™ ì •ë¦¬
"""

import os
import json
import re
import shutil
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict, Counter

class PARAOrganizer:
    def __init__(self, config_path="config.txt"):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ ë° ì´ˆê¸°í™”"""
        self.config = self.load_config(config_path)
        self.vault_path = Path(self.config['VAULT_PATH'])
        self.para_root = self.vault_path / self.config['PARA_ROOT']
        self.output_dir = Path("output")
        self.output_dir.mkdir(exist_ok=True)
        self.files_data = []
        
        # PARA êµ¬ì¡° ì •ì˜
        self.para_structure = {
            '000 Meta': ['Dashboard.md', 'MOC', 'About'],
            '100 Projects': ['Active', 'Planning', 'Completed'],
            '200 Areas': ['Work', 'Personal', 'Health', 'Finance'],
            '300 Resources': ['Inbox', 'Literature Notes', 'Permanent Notes', 'References'],
            '400 Archive': [],
            '900 Templates': [],
            '_attachments': []
        }
    
    def load_config(self, config_path):
        """config.txt ë¡œë“œ"""
        config = {}
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        config[key.strip()] = value.strip()
            
            # í•„ìˆ˜ ì„¤ì • í™•ì¸
            if not config.get('VAULT_PATH'):
                raise Exception("VAULT_PATHê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            config.setdefault('PARA_ROOT', 'PARA_System')
            config.setdefault('CREATE_BACKUP', 'true')
            config.setdefault('AUTO_MOVE', 'true')
            config.setdefault('INBOX_DAYS', '7')
            config.setdefault('ARCHIVE_DAYS', '90')
            
            return config
        except Exception as e:
            raise Exception(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def create_para_structure(self):
        """PARA í´ë” êµ¬ì¡° ìƒì„±"""
        print("\nğŸ“ PARA êµ¬ì¡° ìƒì„± ì¤‘...")
        
        # ë£¨íŠ¸ í´ë” ìƒì„±
        self.para_root.mkdir(exist_ok=True)
        
        created_count = 0
        for folder, subfolders in self.para_structure.items():
            folder_path = self.para_root / folder
            folder_path.mkdir(exist_ok=True)
            created_count += 1
            
            # í•˜ìœ„ í´ë” ìƒì„±
            for subfolder in subfolders:
                if subfolder.endswith('.md'):
                    # íŒŒì¼ ìƒì„±
                    file_path = folder_path / subfolder
                    if not file_path.exists():
                        file_path.write_text(f"# {subfolder.replace('.md', '')}\n\n", encoding='utf-8')
                else:
                    # í´ë” ìƒì„±
                    sub_path = folder_path / subfolder
                    sub_path.mkdir(exist_ok=True)
                    created_count += 1
        
        print(f"âœ“ {created_count}ê°œ í´ë”/íŒŒì¼ ìƒì„± ì™„ë£Œ\n")
    
    def scan_vault(self):
        """ë³¼íŠ¸ì˜ ëª¨ë“  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìŠ¤ìº”"""
        print("ğŸ“‚ ë³¼íŠ¸ ìŠ¤ìº” ì¤‘...")
        
        md_files = []
        for file_path in self.vault_path.rglob("*.md"):
            # PARA í´ë” ë‚´ë¶€ íŒŒì¼ì€ ì œì™¸
            if str(file_path).startswith(str(self.para_root)):
                continue
            # ìˆ¨ê¹€ íŒŒì¼ ì œì™¸
            if any(part.startswith('.') for part in file_path.parts):
                continue
            md_files.append(file_path)
        
        print(f"âœ“ {len(md_files)}ê°œ íŒŒì¼ ë°œê²¬\n")
        return md_files
    
    def extract_metadata(self, file_path):
        """íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            metadata = {
                'path': str(file_path),
                'name': file_path.name,
                'title': file_path.stem,
                'content': content,
                'tags': [],
                'yaml': {},
                'links': [],
                'word_count': len(content.split()),
                'created': datetime.fromtimestamp(file_path.stat().st_ctime),
                'modified': datetime.fromtimestamp(file_path.stat().st_mtime)
            }
            
            # YAML frontmatter ì¶”ì¶œ
            yaml_match = re.match(r'^---\n(.*?)\n---', content, re.DOTALL)
            if yaml_match:
                yaml_text = yaml_match.group(1)
                for line in yaml_text.split('\n'):
                    if ':' in line:
                        key, value = line.split(':', 1)
                        metadata['yaml'][key.strip()] = value.strip()
                
                # YAMLì—ì„œ íƒœê·¸ ì¶”ì¶œ
                if 'tags' in metadata['yaml']:
                    tags_str = metadata['yaml']['tags']
                    # [tag1, tag2] í˜•ì‹ ì²˜ë¦¬
                    tags_str = tags_str.strip('[]')
                    metadata['tags'].extend([t.strip().strip('"\'') for t in tags_str.split(',')])
            
            # ë³¸ë¬¸ì—ì„œ #íƒœê·¸ ì¶”ì¶œ
            hash_tags = re.findall(r'#(\w+)', content)
            metadata['tags'].extend(hash_tags)
            metadata['tags'] = list(set(metadata['tags']))  # ì¤‘ë³µ ì œê±°
            
            # [[ë§í¬]] ì¶”ì¶œ
            links = re.findall(r'\[\[([^\]]+)\]\]', content)
            metadata['links'] = links
            metadata['link_count'] = len(links)
            
            return metadata
        except Exception as e:
            print(f"âš ï¸ {file_path.name} ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def classify_file(self, metadata):
        """íŒŒì¼ì„ PARA ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜"""
        tags = [t.lower() for t in metadata['tags']]
        yaml = {k.lower(): v.lower() for k, v in metadata['yaml'].items()}
        content_lower = metadata['content'][:1000].lower()
        title_lower = metadata['title'].lower()
        
        # 1. ëª…ì‹œì  íƒœê·¸ ìš°ì„ 
        if 'archive' in tags or yaml.get('status') == 'archived':
            return '400 Archive', ''
        
        if 'project' in tags or yaml.get('type') == 'project':
            status = yaml.get('status', 'active')
            if status == 'completed':
                return '100 Projects', 'Completed'
            elif status == 'planning':
                return '100 Projects', 'Planning'
            else:
                return '100 Projects', 'Active'
        
        # 2. Areas ë¶„ë¥˜
        if 'work' in tags or 'business' in tags:
            return '200 Areas', 'Work'
        if 'personal' in tags or 'life' in tags:
            return '200 Areas', 'Personal'
        if 'health' in tags or 'fitness' in tags:
            return '200 Areas', 'Health'
        if 'finance' in tags or 'money' in tags:
            return '200 Areas', 'Finance'
        
        # 3. Resources ë¶„ë¥˜
        # Literature Notes
        if any(tag in tags for tag in ['book', 'article', 'video', 'paper']):
            return '300 Resources', 'Literature Notes'
        if 'source' in yaml or 'author' in yaml:
            return '300 Resources', 'Literature Notes'
        
        # Permanent Notes (ë†’ì€ ë§í¬ ë°€ë„)
        if metadata['link_count'] >= 5:
            return '300 Resources', 'Permanent Notes'
        
        # References
        if 'reference' in tags or 'ref' in tags:
            return '300 Resources', 'References'
        
        # Inbox (ìµœê·¼ ìƒì„±, íƒœê·¸ ì—†ìŒ)
        inbox_threshold = datetime.now() - timedelta(days=int(self.config['INBOX_DAYS']))
        if metadata['created'] > inbox_threshold and len(metadata['tags']) == 0:
            return '300 Resources', 'Inbox'
        
        # 4. í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        # Project í‚¤ì›Œë“œ
        project_keywords = ['í”„ë¡œì íŠ¸', 'project', 'ë§ˆê°', 'deadline', 'ëª©í‘œ', 'goal']
        if any(kw in title_lower or kw in content_lower for kw in project_keywords):
            return '100 Projects', 'Active'
        
        # Area í‚¤ì›Œë“œ
        work_keywords = ['ì—…ë¬´', 'work', 'íšŒì‚¬', 'company', 'ì§ì¥', 'office']
        if any(kw in title_lower or kw in content_lower for kw in work_keywords):
            return '200 Areas', 'Work'
        
        # 5. ê¸°ë³¸ê°’: Resources/References
        return '300 Resources', 'References'
    
    def move_file(self, file_path, category, subcategory):
        """íŒŒì¼ì„ PARA êµ¬ì¡°ë¡œ ì´ë™"""
        target_dir = self.para_root / category
        if subcategory:
            target_dir = target_dir / subcategory
        
        target_dir.mkdir(parents=True, exist_ok=True)
        target_path = target_dir / file_path.name
        
        # ë™ì¼í•œ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if target_path.exists():
            # íŒŒì¼ ë‚´ìš© ë¹„êµ
            try:
                with open(file_path, 'r', encoding='utf-8') as f1:
                    content1 = f1.read()
                with open(target_path, 'r', encoding='utf-8') as f2:
                    content2 = f2.read()
                
                if content1 == content2:
                    # ë™ì¼í•œ íŒŒì¼ì´ë©´ ì›ë³¸ ì‚­ì œí•˜ê³  ê±´ë„ˆë›°ê¸°
                    file_path.unlink()
                    return True, target_path, 'skipped'
                else:
                    # ë‚´ìš©ì´ ë‹¤ë¥´ë©´ ë²ˆí˜¸ ë¶™ì—¬ì„œ ì´ë™
                    base = target_path.stem
                    ext = target_path.suffix
                    counter = 1
                    while target_path.exists():
                        target_path = target_dir / f"{base}_{counter}{ext}"
                        counter += 1
            except:
                # ë¹„êµ ì‹¤íŒ¨ ì‹œ ë²ˆí˜¸ ë¶™ì´ê¸°
                base = target_path.stem
                ext = target_path.suffix
                counter = 1
                while target_path.exists():
                    target_path = target_dir / f"{base}_{counter}{ext}"
                    counter += 1
        
        try:
            shutil.move(str(file_path), str(target_path))
            return True, target_path, 'moved'
        except Exception as e:
            print(f"âš ï¸ {file_path.name} ì´ë™ ì‹¤íŒ¨: {e}")
            return False, None, 'failed'
    
    def organize_vault(self):
        """ë³¼íŠ¸ ì „ì²´ ì •ë¦¬"""
        # PARA êµ¬ì¡° ìƒì„±
        self.create_para_structure()
        
        # íŒŒì¼ ìŠ¤ìº”
        files = self.scan_vault()
        
        # ë¶„ë¥˜ ë° ì´ë™
        print("ğŸ“Š íŒŒì¼ ë¶„ë¥˜ ë° ì´ë™ ì¤‘...")
        
        classification = defaultdict(lambda: defaultdict(int))
        moved_count = 0
        skipped_count = 0
        failed_count = 0
        
        for i, file_path in enumerate(files, 1):
            print(f"\rì§„í–‰: {i}/{len(files)} ({i/len(files)*100:.1f}%)", end="")
            
            metadata = self.extract_metadata(file_path)
            if not metadata:
                failed_count += 1
                continue
            
            category, subcategory = self.classify_file(metadata)
            classification[category][subcategory] += 1
            
            # ìë™ ì´ë™ ì„¤ì • í™•ì¸
            if self.config['AUTO_MOVE'].lower() == 'true':
                success, new_path, status = self.move_file(file_path, category, subcategory)
                if success:
                    if status == 'skipped':
                        skipped_count += 1
                    else:
                        moved_count += 1
                    metadata['new_path'] = str(new_path)
                    metadata['category'] = category
                    metadata['subcategory'] = subcategory
                    self.files_data.append(metadata)
                else:
                    failed_count += 1
        
        print(f"\nâœ“ {moved_count}ê°œ íŒŒì¼ ì´ë™ ì™„ë£Œ")
        if skipped_count > 0:
            print(f"â­ï¸ {skipped_count}ê°œ ì¤‘ë³µ íŒŒì¼ ê±´ë„ˆëœ€\n")
        else:
            print()
        
        # ë¶„ë¥˜ ê²°ê³¼ ì¶œë ¥
        print("ğŸ“Š ë¶„ë¥˜ ê²°ê³¼:")
        for category in sorted(classification.keys()):
            total = sum(classification[category].values())
            print(f"\n  {category}: {total}ê°œ")
            for subcat, count in sorted(classification[category].items()):
                if subcat:
                    print(f"    - {subcat}: {count}ê°œ")
        
        if failed_count > 0:
            print(f"\nâš ï¸ ì‹¤íŒ¨: {failed_count}ê°œ")
        
        # ìŠ¤ëƒ…ìƒ· ì €ì¥
        self.save_snapshot()
        
        # MOC ë° Dashboard ìƒì„±
        self.create_mocs()
        self.create_dashboard()
    
    def create_mocs(self):
        """MOC (Map of Content) ìƒì„±"""
        print("\nğŸ“ MOC ìƒì„± ì¤‘...")
        
        moc_dir = self.para_root / '000 Meta' / 'MOC'
        moc_dir.mkdir(exist_ok=True)
        
        # ì¹´í…Œê³ ë¦¬ë³„ MOC
        by_category = defaultdict(list)
        for file_data in self.files_data:
            category = file_data.get('category', '')
            if category:
                by_category[category].append(file_data)
        
        moc_count = 0
        for category, files in by_category.items():
            moc_path = moc_dir / f"{category.replace(' ', '_')}_MOC.md"
            
            content = [f"# {category} - Map of Content\n\n"]
            content.append(f"> ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n")
            
            # í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
            by_subcat = defaultdict(list)
            for f in files:
                subcat = f.get('subcategory', 'Other')
                by_subcat[subcat].append(f)
            
            for subcat in sorted(by_subcat.keys()):
                content.append(f"## {subcat}\n\n")
                for f in sorted(by_subcat[subcat], key=lambda x: x['title']):
                    # ìƒëŒ€ ê²½ë¡œë¡œ ë§í¬ ìƒì„±
                    rel_path = Path(f['new_path']).relative_to(self.para_root)
                    content.append(f"- [[{rel_path}|{f['title']}]]\n")
                content.append("\n")
            
            moc_path.write_text(''.join(content), encoding='utf-8')
            moc_count += 1
        
        print(f"âœ“ {moc_count}ê°œ MOC ìƒì„± ì™„ë£Œ")
    
    def create_dashboard(self):
        """Dashboard ìƒì„±"""
        print("ğŸ“Š Dashboard ìƒì„± ì¤‘...")
        
        dashboard_path = self.para_root / '000 Meta' / 'Dashboard.md'
        
        content = []
        content.append("# ğŸ“Š PARA Dashboard\n\n")
        content.append(f"> ìµœì¢… ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n")
        
        # í†µê³„
        content.append("## ğŸ“ˆ í†µê³„\n\n")
        content.append(f"- ì´ íŒŒì¼: {len(self.files_data)}ê°œ\n")
        
        by_category = Counter(f.get('category', '') for f in self.files_data)
        for category, count in sorted(by_category.items()):
            content.append(f"- {category}: {count}ê°œ\n")
        
        # Quick Links
        content.append("\n## ğŸ”— Quick Links\n\n")
        content.append("- [[000 Meta/MOC/|MOC í´ë”]]\n")
        content.append("- [[100 Projects/Active/|ì§„í–‰ ì¤‘ì¸ í”„ë¡œì íŠ¸]]\n")
        content.append("- [[300 Resources/Inbox/|Inbox]]\n")
        content.append("- [[400 Archive/|Archive]]\n")
        
        # ìµœê·¼ íŒŒì¼
        content.append("\n## ğŸ“Œ ìµœê·¼ ìˆ˜ì • (TOP 10)\n\n")
        recent = sorted(self.files_data, key=lambda x: x['modified'], reverse=True)[:10]
        for f in recent:
            rel_path = Path(f['new_path']).relative_to(self.para_root)
            mod_date = f['modified'].strftime('%Y-%m-%d')
            content.append(f"- [[{rel_path}|{f['title']}]] - {mod_date}\n")
        
        dashboard_path.write_text(''.join(content), encoding='utf-8')
        print("âœ“ Dashboard ìƒì„± ì™„ë£Œ")
    
    def save_snapshot(self):
        """ìŠ¤ëƒ…ìƒ· ì €ì¥"""
        snapshot_file = self.output_dir / f"snapshot_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
        
        # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        serializable_data = []
        for file_data in self.files_data:
            data_copy = file_data.copy()
            if 'created' in data_copy and isinstance(data_copy['created'], datetime):
                data_copy['created'] = data_copy['created'].isoformat()
            if 'modified' in data_copy and isinstance(data_copy['modified'], datetime):
                data_copy['modified'] = data_copy['modified'].isoformat()
            serializable_data.append(data_copy)
        
        with open(snapshot_file, 'w', encoding='utf-8') as f:
            json.dump({
                'date': datetime.now().isoformat(),
                'total_files': len(serializable_data),
                'files': serializable_data
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ“ ìŠ¤ëƒ…ìƒ· ì €ì¥: {snapshot_file.name}")


def main():
    print("\n" + "="*60)
    print("ğŸ—‚ï¸ Obsidian PARA Organizer")
    print("="*60 + "\n")
    
    try:
        organizer = PARAOrganizer()
        
        print(f"ğŸ“‚ ë³¼íŠ¸ ê²½ë¡œ: {organizer.vault_path}")
        print(f"ğŸ“ PARA ë£¨íŠ¸: {organizer.para_root}\n")
        
        # ë°±ì—… ìƒì„±
        if organizer.config['CREATE_BACKUP'].lower() == 'true':
            print("ğŸ’¾ ë°±ì—… ìƒì„± ì¤‘...")
            backup_dir = organizer.vault_path / f"_backup_{datetime.now().strftime('%Y%m%d_%H%M')}"
            # ê°„ë‹¨í•œ ë°±ì—…: PARA í´ë”ë§Œ ë°±ì—…
            if organizer.para_root.exists():
                shutil.copytree(organizer.para_root, backup_dir / organizer.config['PARA_ROOT'])
                print(f"âœ“ ë°±ì—… ì™„ë£Œ: {backup_dir.name}\n")
        
        start_time = datetime.now()
        
        # ë³¼íŠ¸ ì •ë¦¬
        organizer.organize_vault()
        
        elapsed = (datetime.now() - start_time).total_seconds()
        
        print("\n" + "="*60)
        print("âœ… ì™„ë£Œ!")
        print("="*60)
        print(f"ì²˜ë¦¬ëœ íŒŒì¼: {len(organizer.files_data)}ê°œ")
        print(f"ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")
        print(f"PARA ê²½ë¡œ: {organizer.para_root}")
        print("="*60 + "\n")
        
    except Exception as e:
        print(f"\nâœ— ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    input("\nì•„ë¬´ í‚¤ë‚˜ ëˆŒëŸ¬ ì¢…ë£Œ...")


if __name__ == "__main__":
    main()
