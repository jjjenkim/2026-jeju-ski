import requests
from bs4 import BeautifulSoup
import json
import time
import random
import re

# =========================================================
# 1. TEAM KOREA ëª…ë‹¨ ë°ì´í„° (ë„¤ê°€ ì¤€ ê±° ê·¸ëŒ€ë¡œ ë„£ìŒ)
# =========================================================
RAW_TEAM_DATA = """
## **í”„ë¦¬ìŠ¤íƒ€ì¼ ìŠ¤í‚¤ í•˜í”„íŒŒì´í”„Â·ìŠ¬ë¡œí”„ìŠ¤íƒ€ì¼ êµ­ê°€ëŒ€í‘œ**
- ì´ìŠ¹í›ˆ(05) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=FS&competitorid=235622&type=result
- ë¬¸í¬ì„±(06) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=FS&competitorid=239278&type=result
- ì‹ ì˜ì„­(05) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=FS&competitorid=233691&type=result
- ì¥ìœ ì§„(01) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=FS&competitorid=203633&type=result
- ê¹€ë‹¤ì€(05) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=FS&competitorid=235623&type=result

## **í”„ë¦¬ìŠ¤íƒ€ì¼ ëª¨ê¸€ êµ­ê°€ëŒ€í‘œ**
- ì •ëŒ€ìœ¤(05) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=FS&competitorid=229480&type=result
- ì´ìœ¤ìŠ¹(06) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=FS&competitorid=252896&type=result
- ìœ¤ì‹ ì´(07) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=FS&competitorid=258758&type=result

## **ìŠ¤ë…¸ë³´ë“œ ì•ŒíŒŒì¸ êµ­ê°€ëŒ€í‘œ**
- ì´ìƒí˜¸(95) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=163744&type=result
- ê¹€ìƒê²¸(89) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=111837&type=result
- ì¡°ì™„í¬(98) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=188938&type=result
- ë§ˆì¤€í˜¸(02) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=220950&type=result
- í™ìŠ¹ì˜(98) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=188936&type=result
- ì •í•´ë¦¼(95) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=156415&type=result

## **ìŠ¤ë…¸ë³´ë“œ í¬ë¡œìŠ¤ êµ­ê°€ëŒ€í‘œ**
- ìš°ìˆ˜ë¹ˆ(03) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=229485&type=result

## **ìŠ¤ë…¸ë³´ë“œ í•˜í”„íŒŒì´í”„Â·ìŠ¬ë¡œí”„ìŠ¤íƒ€ì¼Â·ë¹…ì—ì–´ êµ­ê°€ëŒ€í‘œ**
- ì´ì±„ìš´(06) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=239112&type=result
- ì´ì§€ì˜¤(08) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=261333&type=result
- ê¹€ê±´í¬(08) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=261977&type=result
- ìµœê°€ì˜¨(08) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=264594&type=result
- ì´ë‚˜ìœ¤(03) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=212759&type=result
- ì´ë™í—Œ(06) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=239111&type=result
- ìœ ìŠ¹ì€(08) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=SB&competitorid=261339&type=result

## **ìŠ¤í‚¤ì í”„ êµ­ê°€ëŒ€í‘œ**
- ìµœí¥ì² (81) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=JP&competitorid=10064&type=result
- ì¥ì„ ì›…(07) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=JP&competitorid=270266&type=result

## **í¬ë¡œìŠ¤ì»¨íŠ¸ë¦¬ êµ­ê°€ëŒ€í‘œ**
- ì´ì¤€ì„œ(03) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=CC&competitorid=229479&type=result
- ë³€ì§€ì˜(98) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=CC&competitorid=188923&type=result
- ì´ì§„ë³µ(02) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=CC&competitorid=229490&type=result
- ì •ì¢…ì›(92) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=CC&competitorid=136287&type=result
- ì´ê±´ìš©(93) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=CC&competitorid=154934&type=result
- ì´ì˜ì§„(01) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=CC&competitorid=221223&type=result
- í•œë‹¤ì†œ(94) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=CC&competitorid=162284&type=result
- ì´ì§€ì˜ˆ(01) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=CC&competitorid=212563&type=result
- ì œìƒë¯¸(99) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=CC&competitorid=195562&type=result

## **ì•ŒíŒŒì¸ êµ­ê°€ëŒ€í‘œ**
- ì •ë™í˜„(88) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=AL&competitorid=93945&type=result
- ë°•ì œìœ¤(94) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=AL&competitorid=154866&type=result
- í™ë™ê´€(95) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=AL&competitorid=163737&type=result
- ê¹€ë™ìš°(95) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=AL&competitorid=163740&type=result
- ì •ë¯¼ì‹(97) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=AL&competitorid=189170&type=result
- ì´í•œí¬(97) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=AL&competitorid=188824&type=result
- ì‹ ì •ìš°(99) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=AL&competitorid=203604&type=result
- ê¹€ì†Œí¬(96) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=AL&competitorid=177571&type=result
- ìµœíƒœí¬(05) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=AL&competitorid=263315&type=result
- ë°•ì„œìœ¤(05) â€”
https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=AL&competitorid=261321&type=result
"""

# =========================================================
# 2. ì •ë°€ í•„í„°ë§ ì„¤ì • (ì¢…ëª© / ë“±ê¸‰ êµ¬ë¶„ìš©)
# =========================================================
# FIS ì‚¬ì´íŠ¸ì—ì„œ ì´ ë‹¨ì–´ë“¤ì´ ë³´ì´ë©´ ë¬´ì¡°ê±´ 'ì¢…ëª©'ìœ¼ë¡œ ì¸ì‹
VALID_DISCIPLINES = [
    "Moguls", "Dual Moguls", "Dual Moguls Team", "Aerials", "Aerials Team",
    "Ski Cross", "Ski Cross Team", "Freeski Halfpipe", "Freeski Slopestyle",
    "Freeski Big Air", "Snowboard Cross", "Snowboard Cross Team", "Snowboard Halfpipe",
    "Snowboard Slopestyle", "Snowboard Big Air",
    "Giant Slalom", "Slalom", "Super G", "Downhill", "Alpine Combined",
    "Parallel Giant Slalom", "Parallel Slalom", "Parallel Giant Slalom Team",
    "Sprint Free", "Sprint Classic", "10km Interval Start Free", "10km Interval Start Classic",
    "15km Mass Start Free", "Ski Jumping", "Flying Hill", "Large Hill", "Normal Hill"
]

# FIS ì‚¬ì´íŠ¸ì—ì„œ ì´ ë‹¨ì–´ë“¤ì´ ë³´ì´ë©´ ë¬´ì¡°ê±´ 'ëŒ€íšŒ ë“±ê¸‰(Category)'ìœ¼ë¡œ ì¸ì‹ (ì ˆëŒ€ ì•ˆ ë²„ë¦¼)
VALID_CATEGORIES = [
    "WC", "WSC", "FIS", "NC", "EC", "YOG", "WJC", "AC", "OPN", "NAC", "SAC", "ANC", "FEC", "OWG", "UVS"
]

# =========================================================
# 3. í•µì‹¬ ë¡œì§ í•¨ìˆ˜
# =========================================================

def parse_team_data(raw_text):
    """í•œê¸€ ëª…ë‹¨ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•´ì„œ êµ¬ì¡°í™”ëœ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    athletes = []
    current_category = "Unknown"
    
    lines = raw_text.split('\n')
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        if line.startswith("##"):
            current_category = line.replace("##", "").replace("**", "").strip()
            i += 1
            continue
            
        # ì„ ìˆ˜ ì´ë¦„ ë¼ì¸ ê°ì§€ (ì˜ˆ: "- ì´ìŠ¹í›ˆ(05) â€”")
        if line.startswith("-") and "(" in line:
            name_part = line.split("â€”")[0].replace("-", "").strip()
            # ì´ë¦„ê³¼ ìƒë…„ ë¶„ë¦¬
            match = re.match(r"([ê°€-í£]+)\((\d+)\)", name_part)
            if match:
                name_kr = match.group(1)
                birth_year = match.group(2)
                
                # ë‹¤ìŒ ì¤„ì´ URLì¸ì§€ í™•ì¸
                if i + 1 < len(lines) and "http" in lines[i+1]:
                    url = lines[i+1].strip()
                    # URLì—ì„œ ID ì¶”ì¶œ
                    id_match = re.search(r"competitorid=(\d+)", url)
                    athlete_id = id_match.group(1) if id_match else f"TEMP_{random.randint(1000,9999)}"
                    
                    athletes.append({
                        "id": athlete_id,
                        "name_kr": name_kr,
                        "birth_year": birth_year,
                        "team_category": current_category,
                        "fis_url": url
                    })
                    i += 1 # URL ì¤„ ê±´ë„ˆë›°ê¸°
        i += 1
    return athletes

def parse_row_text(cols):
    """
    [í•µì‹¬] FIS í…Œì´ë¸” í•œ ì¤„(Row)ì„ ë¶„ì„í•´ì„œ 
    ë‚ ì§œ, ì¥ì†Œ, ì¢…ëª©, ë“±ê¸‰, ìˆœìœ„ë¥¼ ì •í™•íˆ ë°œë¼ë‚´ëŠ” í•„í„°
    """
    data = {
        "date": "-", "place": "-", "discipline": "Unknown", 
        "category": "-", "rank": 0
    }
    
    # 1. ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë¹ˆì¹¸ ì œì™¸)
    all_texts = [col.get_text(strip=True) for col in cols if col.get_text(strip=True)]
    if not all_texts: return None

    # [Rule 1] ë‚ ì§œ: ë¬´ì¡°ê±´ ì²« ë²ˆì§¸ ë°ì´í„°
    data['date'] = all_texts[0]

    # ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸ ë¶„ì„
    remaining_texts = all_texts[1:]
    
    # [Rule 2 & 3] ì¢…ëª©ê³¼ ë“±ê¸‰ ì°¾ê¸°
    for text in remaining_texts:
        clean_text = text.strip()
        
        # ì¢…ëª© ì‚¬ì „ ëŒ€ì¡°
        for disc in VALID_DISCIPLINES:
            if disc.lower() in clean_text.lower():
                data['discipline'] = disc # ì •í™•í•œ ì¢…ëª©ëª… ë§¤í•‘
                break
        
        # ë“±ê¸‰ ì‚¬ì „ ëŒ€ì¡°
        if clean_text in VALID_CATEGORIES:
            data['category'] = clean_text

    # [Rule 4] ì¥ì†Œ ì°¾ê¸° (ì†Œê±°ë²•: ë‚ ì§œ/ì¢…ëª©/ë“±ê¸‰/ìˆœìœ„ê°€ ì•„ë‹Œ ê²ƒ ì¤‘ ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸)
    candidates = []
    for text in remaining_texts:
        t = text.strip()
        is_digit = t.isdigit()
        is_disc = any(d.lower() in t.lower() for d in VALID_DISCIPLINES)
        is_cat = t in VALID_CATEGORIES
        
        if not is_digit and not is_disc and not is_cat:
            candidates.append(t)
    
    if candidates:
        # ê°€ì¥ ê¸´ ë¬¸ìì—´ì„ ì¥ì†Œë¡œ ì„ íƒ (ë³´í†µ ì¥ì†Œëª…ì´ ê¸º)
        data['place'] = max(candidates, key=len)

    # [Rule 5] ìˆœìœ„: ë§ˆì§€ë§‰ ì¹¸ì˜ ì²« ë²ˆì§¸ ìˆ«ì
    try:
        score_box = cols[-1].find_all("div", recursive=False)
        rank_text = score_box[0].get_text(strip=True) if score_box else "0"
        
        if rank_text.isdigit():
            data['rank'] = int(rank_text)
        else:
            return None # ìˆœìœ„ê°€ ì—†ê±°ë‚˜ DNFë©´ ë°ì´í„°ì—ì„œ ì œì™¸
    except:
        return None

    # í•„ìˆ˜ ë°ì´í„° ì—†ìœ¼ë©´ ë²„ë¦¼ (ì¢…ëª©ì´ Unknownì´ë©´ ì¥ì†Œê°€ ì˜ëª» ë“¤ì–´ê°„ ê²ƒì¼ ìˆ˜ ìˆìŒ)
    if data['discipline'] == "Unknown":
        # ì¶”ê°€ ë³´ì •: í…ìŠ¤íŠ¸ ì¤‘ Disciplinesì— í¬í•¨ë˜ëŠ”ê²Œ ìˆëŠ”ì§€ ë‹¤ì‹œ í™•ì¸
        pass 

    return data

def get_photo_url(soup):
    """CSS background-imageì—ì„œ URL ì¶”ì¶œ"""
    img_div = soup.find("div", class_="avatar__image")
    if img_div and 'style' in img_div.attrs:
        match = re.search(r"url\('([^']+)'\)", img_div['style'])
        if match: return match.group(1)
    return "https://via.placeholder.com/150?text=No+Image"

# =========================================================
# 4. ì‹¤í–‰ ë¶€ (MAIN)
# =========================================================
def main():
    print("ğŸ”¥ Team Korea ë°ì´í„° íŒŒì´í”„ë¼ì¸ ê°€ë™...")
    
    # 1. í•œê¸€ ëª…ë‹¨ íŒŒì‹±
    target_athletes = parse_team_data(RAW_TEAM_DATA)
    print(f"ğŸ‘‰ ì´ {len(target_athletes)}ëª…ì˜ ì„ ìˆ˜ ëª…ë‹¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    final_data = []

    # 2. FIS í¬ë¡¤ë§ ë° ë°ì´í„° ë³‘í•©
    for idx, athlete in enumerate(target_athletes):
        print(f"[{idx+1}/{len(target_athletes)}] ë°ì´í„° ìˆ˜ì§‘ ì¤‘: {athlete['name_kr']} ({athlete['team_category']})...", end="\r")
        
        try:
            # FIS ì ‘ì†
            res = requests.get(athlete['fis_url'], headers=headers, timeout=10)
            if res.status_code != 200: continue
            
            soup = BeautifulSoup(res.text, 'html.parser')
            
            # [A] FIS ì˜ë¬¸ ì´ë¦„ ë° ì‚¬ì§„ ê°€ì ¸ì˜¤ê¸°
            name_en_tag = soup.find("h1", class_="athlete-profile__name")
            name_en = name_en_tag.get_text(" ", strip=True) if name_en_tag else "Unknown"
            photo_url = get_photo_url(soup)
            
            # [B] ê²½ê¸° ê¸°ë¡ ì •ë°€ ì¶”ì¶œ
            records = []
            rows = soup.find_all("a", class_="table-row")
            
            for row in rows:
                container = row.find("div", class_="container")
                if not container: continue
                
                cols = container.find_all("div", recursive=False)
                row_data = parse_row_text(cols) # ì •ë°€ í•„í„° ì ìš©
                
                if row_data:
                    records.append(row_data)
            
            # ìµœì‹ ìˆœ -> ê³¼ê±°ìˆœ (ì°¨íŠ¸ìš©ìœ¼ë¡œ ì •ë ¬ ë³€ê²½ í•„ìš”ì‹œ ì—¬ê¸°ì„œ reverse)
            # ë³´í†µ ì°¨íŠ¸ëŠ” ì™¼ìª½(ê³¼ê±°) -> ì˜¤ë¥¸ìª½(í˜„ì¬)ì´ë¯€ë¡œ reverse() ì¶”ì²œ
            records.reverse()

            # [C] ë°ì´í„° ë³‘í•© (Merge)
            final_data.append({
                "id": athlete['id'],
                "name_kr": athlete['name_kr'],
                "name_en": name_en,
                "birth_year": athlete['birth_year'],
                "team_category": athlete['team_category'],
                "photo": photo_url,
                "records": records # ì •ì œëœ ê¸°ë¡ ë¦¬ìŠ¤íŠ¸
            })
            
            time.sleep(random.uniform(0.5, 1.0)) # ì°¨ë‹¨ ë°©ì§€ ë”œë ˆì´

        except Exception as e:
            print(f"\nâŒ ì—ëŸ¬ ë°œìƒ ({athlete['name_kr']}): {e}")

    # 3. ê²°ê³¼ ì €ì¥
    output_file = "team_korea_data.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(final_data, f, ensure_ascii=False, indent=4)

    print(f"\nâœ… ì™„ë£Œ! '{output_file}' íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("ğŸ‘‰ ì´ JSON íŒŒì¼ì„ ëŒ€ì‹œë³´ë“œì— ì—°ê²°í•˜ë©´ í•œê¸€ ì´ë¦„ê³¼ ì •í™•í•œ ê¸°ë¡ì´ ë‚˜ì˜µë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
